---
layout: post
title: '핸즈 온 머신러닝'
category: ml
image: "/assets/img/ml/HandsOnML.webp"
tag: ml
message: "한눈에 보는 머신러닝"
---

- table of contents
{:toc} 

<center><img src="/assets/img/ml/HandsOnML.webp" width="80%" height="80%"></center><br>

- 이번에 **구글 머신러닝 부트캠프 5기**에 합격하게 되어 머신러닝을 공부해보게 되었다. 머신러닝에 대한 사전지식이 거의 없기 때문에 머신러닝의 교과서로 통하는 **핸즈 온 머신러닝**을 통해 배워보기로 하였다.

- 책의 역자이신 박해선 작가님이 손수 올려두신 [한눈에 보는 머신러닝 강좌](https://www.youtube.com/watch?v=kpuRasV_Q9k&list=PLJN246lAkhQjX3LOdLVnfdFaCbGouEBeb&index=1){:target="_blank"}를 참고할 것 같다. 사실 1장을 혼자 읽었을 때 잘 이해하지 못했는데, 강의가 있어서 다행이라고 생각했다. 공부를 계속하면서 종종 포스트를 작성할 것 같다. 

## 머신러닝의 종류

### 1. 훈련 감독 방법 : 지도 학습, 비지도 학습, 준지도 학습, 강화 학습

#### 1-1 지도 학습, 정답이 있는 경우 (분류 / 회귀)

(1) 선형 회귀

(2) 로지스틱 회귀

(3) 서포트 벡터 머신

(4) 결정 트리와 앙상블

(5) 신경망

#### 1-2 비지도 학습, 정답이 없는 경우 (군집 / 시각화)

(1) k - 평균

(2) DBSCAN

(3) PCA

(4) 가우시안 혼합

(5) 오토인코더

#### 1-3 준지도 학습, 정답이 일부만 있는 경우

#### 1-4 강화 학습, 행동의 보상이 있는 경우

### 2. 훈련 시점 : 온라인 학습, 배치 학습

#### 2-1 온라인 학습

- 적은 데이터를 사용해 점진적 훈련

- 실시간 시스템이나 메모리가 부족한 경우 사용

#### 2-2 배치 학습

- 전체 데이터를 사용해 오프라인에서 훈련

- 컴퓨팅 자원이 풍부한 경우 사용

### 3. 모델 생성 : 사례 기반 학습, 모델 기반 학습

#### 3-1 사례 기반 학습

- 샘플을 기억하는 것이 훈련

- 예측을 위해 샘플 사이 유사도 측정

- K 최근접 이웃

#### 3-2 모델 기반 학습

- 이 책은 거의 모델 기반 학습을 다루고 있다.

- 샘플을 사용해 모델 훈련

- 훈련된 모델을 사용해 예측

##### 선형 모델

- 종속 변수 = $\theta_0 + \theta_1 \times$ 독립 변수

- $\theta_0, \theta_1$와 같은 매개 변수들을 **모델 파라미터**라고 한다.

#### 요약

- 데이터 준비(특성, 타겟) -> 모델 선택(선형 회귀) -> 모델 훈련(fit 메서드 호출) -> 새로운 데이터에 대한 예측 또는 추론(inference)

## 머신러닝의 주요 도전 과제 (53p)

### 충분하지 않은 양의 훈련 데이터

- 간단한 문제라도 수 천개의 데이터 필요
- 이미지나 음성 인식같은 문제는 수백만 개가 필요할 수 있다.
- 충분한 양의 훈련 데이터는 딥러닝 발전의 원동력이다.

### 대표성 없는 훈련 데이터

- 우연에 의해 대표성이 없는 데이터를 샘플링 잡음이라고 한다.
- 표본 추출 방법이 잘못된 대표성이 없는 데이터를 샘플링 편향이라고 한다.

### 낮은 품질의 데이터

- 이상치 샘플이라면 고치거나 무시한다.
- 특성이 누락되었을 때, 
    (1) 해당 특성을 제외
    (2) 해당 샘플을 제외
    (3) 누락된 값을 채움
    (4) 해당 특성을 넣은 경우와 뺀 경우 각기 모델을 훈련

### 관련 없는 특성

- 특성 공학은 해결하려는 문제에 관련도가 높은 특성을 찾는다.
    (1) 특성 선택 : 준비되어 있는 특성 중 가장 유용한 특성을 찾는다.
    (2) 특성 추출 : 특성을 조합하여 새로운 특성을 만든다.

### 과대 적합

- 훈련 세트에 너무 잘 맞아 일반화 성능이 낮은 현상이다.
- 규제를 사용해 과대 적합을 감소할 수 있다.

### 과소 적합

- 모델이 너무 단순해서 훈련 세트를 잘 학습하지 못함.
- 해결 방법
    (1) 모델 파라미터가 더 많은 모델을 사용한다.
    (2) 특성 공학으로 더 좋은 특성을 찾는다.
    (3) 규제 강도를 줄인다.

## 테스트와 검증

### 테스트 세트와 검증 세트

- 모델의 일반화 성능을 측정하기 위해 훈련 세트와 테스트 세트로 나눈다.
- 훈련 세트로 모델을 훈련하고, 테스트 세트로 모델의 일반화 성능을 측정한다.
- 하이퍼 파라미터는 알고리즘을 조절하기 위해 사전에 정의하는 파라미터이다.
- 테스트 세트를 사용해 여러 모델을 평가하면 테스트 세트에 과대적합된다.
- 모델 선택을 위해 훈련 세트, 검증 세트(개발 세트), 테스트 세트로 나눈다. 

### 훈련-개발 세트

- 대량의 데이터를 얻기 위해 실전과 다른 데이터로 훈련 세트를 만드는 경우.
- 검증 세트 점수가 과대적합과 데이터 불일치 중 어떤 원인인지 모른다.
- 이를 위해 훈련-개발 세트를 만들어 훈련한 모델을 평가한다.

## 연습문제

(1) 머신러닝을 어떻게 정의할 수 있는가

```
- 데이터로부터 학습할 수 있는 시스템을 만드는 것.
- 학습이란 어떤 작업에서 주어진 성능 지표가 더 나아지는 것을 의미한다.
```

(2) 머신러닝이 도움을 줄 수 있는 문제 유형 네 가지

(3) 레이블된 훈련 세트란?

```
- 레이블된 훈련 세트란 각 샘플에 대해 정답을 담고 있는 훈련 세트이다.
```

(4) 가장 널리 사용되는 지도 학습 작업 두 가지

```
- 분류, 회귀
```

(5) 보편적인 비지도 학습 작업 네 가지

```
- 군집, 시각화, 차원 축소, 연관 규칙 학습
```

(6) 사전 정보 없는 여러 지형에서 로봇을 걸어가게 하려면 어떤 종류의 머신러닝 알고리즘을 사용할 수 있는가?

```
- 강화 학습
```

(7) 고객을 여러 그룹으로 분할하려면 어떤 알고리즘을 사용해야 하는가

```
- 군집 알고리즘, 분류 알고리즘
```

(8) 스팸 감지의 문제는 지도 학습과 비지도 학습 중 어떤 문제로 볼 수 있는가

```
- 지도 학습(이메일과 레이블(스팸임, 스팸 아님)이 제공됨)
```

(9) 온라인 학습 시스템은 무엇인가

```
- 배치 학습과 달리 점진적으로 학습함. 
- 변화하는 데이터와 자율 시스템에 빠르게 적응하고 매우 많은 데이터를 훈련시킬 수 있음.
```

(10) 외부 메모리 학습은 무엇인가

```
- 컴퓨터의 주메모리에 들어갈 수 없는 대용량 데이터를 다룰 수 있다.
- 데이터를 미니 배치로 나누고 온라인 학습 기법을 사용해 학습한다.
```

(11) 예측을 하기 위해 유사도 측정에 의존하는 학습 알고리즘은 무엇인가

```
- 사례 기반 학습 시스템은 훈련 데이터를 기억하는 학습이다. 
- 새 샘플이 주어지면 유사도 측정을 통해 학습된 샘플 중에서 가장 비슷한 것을 찾아 
예측으로 사용한다.
```

(12) 모델 파라미터와 학습 알고리즘의 하이퍼파라미터 사이에는 어떤 차이가 있는가

```
- 모델은 하나 이상의 파라미터(선형 모델의 기울기)를 통해 새 샘플이 주어졌을 때 
어떻게 예측할지 결정한다.
- 학습 알고리즘은 모델이 새로운 샘플에 잘 일반화되도록 이런 파라미터들의 최적값을 찾는다.
- 하이퍼 파라미터는 모델이 아니라 이런 학습 알고리즘 자체의 파라미터이다.
```

(13) 모델 기반 알고리즘이 찾는 것은 무엇인가? 성공을 위해 이 알고리즘이 사용하는 가장 일반적인 전략은 무엇인가? 예측은 어떻게 만드는가?

```
- 모델 기반 학습 알고리즘은 새로운 샘플에 잘 일반화되기 위한 모델 파라미터의 최적값을 찾는다.
- 일반적으로 훈련 데이터에서 시스템의 예측을 측정하고, 비용 함수를 최소화하여 시스템을
훈련시킨다. (경사하강?)
- 예측을 만들기 위해 학습 알고리즘이 찾은 파라미터를 사용하는 모델의 예측 함수에 새로운 샘플의 
특성을 주입한다.
```

(14) 머신러닝의 주요 도전과제는 무엇인가?

```
- 부족한 데이터, 낮은 데이터 품질, 대표성 없는 데이터
- 무의미한 특성, 과소 혹은 과대하게 적합한 모델
```

(15) 모델이 훈련 데이터에서 성능은 좋지만 새로운 샘플에서의 일반화 성능이 나쁘다면 어떤 문제가 있는 것인가? 가능한 해결책 세 가지는 무엇인가

```
- 훈련 데이터에서 성능은 좋지만 새로운 샘플에서의 일반화 성능이 나쁘다면 모델이
훈련데이터에 과대적합되었을 가능성이 높다.
- 과대적합을 해결하기 위해 더 많은 데이터를 모으거나, 모델을 단순화하거나
- 간단한 알고리즘을 선택하거나, 파라미터나 특성을 줄이거나 규제를 추가한다.
- 훈련 데이터의 잡음을 감소시킬 수도 있다. 
```

(16) 테스트 세트가 무엇이고 왜 사용해야 하는가

```
- 테스트 세트는 실전에 배치되기 전 모델이 새로운 샘플에 대해 만들 일반화
오차를 추정하기 위해 사용한다.
```

(17) 검증 세트의 목적은 무엇인가

```
- 검증 세트는 모델을 비교하기 위해 사용한다. 
- 가장 좋은 모델을 고르고 하이퍼 파라미터를 만든다.
```

(18) 훈련-개발 세트가 무엇인가, 언제 필요하고 어떻게 사용해야 하는가

```
- 훈련-개발 세트는 훈련 데이터와 실전(검증, 테스트) 세트의 괴리를 줄일 때 사용한다.
- 훈련 세트로 훈련하고, 훈련-개발 세트와 검증 세트에서 평가한다.
- 훈련 세트에서 잘 동작하고, 훈련-개발 세트에서 나쁘다면 훈련 세트에 과대적합 된 것일 수 있다.
- 둘다 잘 동작하지만 검증 세트에서 나쁘다면 훈련 데이터와 실전 테스트 데이터 사이에 
괴리가 있을 가능성이 높다.
- 실전 데이터에 가깝게 되도록 훈련 데이터를 개선한다.
```

(19) 테스트 세트를 사용해 하이퍼 파라미터를 튜닝하면 어떤 문제가 생기는가

```
- 테스트 세트를 사용해 하이퍼 파라미터를 튜닝하면 테스트 세트에 과대적합될 위험이 있고, 
일반화 오차를 낙관적으로 측정하게 된다.
- 실제 출시 시 기대보다 나쁜 성능을 낼 것이다.
```